# Databricks notebook source
# MAGIC %run ../formula_one_through_ADF/cmn_fun

# COMMAND ----------

from pyspark.sql.functions import col,explode


# COMMAND ----------

df = spark.read.option("multiline", "true").json(f"/mnt/sagen2databricks/f1-project/bronze/seasons/",recursiveFileLookup=True)

# COMMAND ----------

df = df.withColumn('list',explode(col('MRData').SeasonTable.Seasons))

# COMMAND ----------

df = df.drop('MRData')


# COMMAND ----------

df = df.withColumn('season',col('list').season).withColumn('url',col('list').url)

df = df.drop('list')
df.display()

# COMMAND ----------

df = df.select('season','url').distinct()
df.count()

# COMMAND ----------

df.write.option('format','delta').mode('overwrite').save('/mnt/sagen2databricks/f1-project/silver/seasons')
